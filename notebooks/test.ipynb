{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ad83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtx5070ti를 지원하는 cuda12.8버전 지정 설치\n",
    "#pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9a2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "Device name: NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16aeac2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Epoch 1/10 ---\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     evaluate(model, device, test_loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, device, train_loader, optimizer, criterion)\u001b[39m\n\u001b[32m     59\u001b[39m optimizer.zero_grad() \u001b[38;5;66;03m# 기울기 초기화\u001b[39;00m\n\u001b[32m     60\u001b[39m output = model(data) \u001b[38;5;66;03m# 순전파\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 손실 계산\u001b[39;00m\n\u001b[32m     62\u001b[39m loss.backward() \u001b[38;5;66;03m# 역전파\u001b[39;00m\n\u001b[32m     63\u001b[39m optimizer.step() \u001b[38;5;66;03m# 가중치 업데이트\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rladud\\anaconda3\\envs\\pytouch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1740\u001b[39m, in \u001b[36m_wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rladud\\anaconda3\\envs\\pytouch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36m_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rladud\\anaconda3\\envs\\pytouch-env\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rladud\\anaconda3\\envs\\pytouch-env\\Lib\\site-packages\\torch\\nn\\functional.py:3489\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3488\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3489\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3490\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3493\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 1. GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. 하이퍼파라미터 설정 (모델 학습에 필요한 설정값들)\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "# 3. 데이터 로더 준비\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 4. 신경망 모델 정의\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # 첫 번째 레이어: 입력층 (28*28) -> 은닉층 128개\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        # 두 번째 레이어: 은닉층 128개 -> 은닉층 64개\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # 세 번째 레이어: 은닉층 64개 -> 출력층 10개 (0~9까지의 숫자)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 텐서를 1차원으로 펼치기 (Flatten)\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # 활성화 함수 ReLU를 적용\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        # 마지막 출력층\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "\n",
    "    def forward(self, x):\n",
    "        # 데이터가 모델을 통과하는 과정을 정의해야 함\n",
    "        return x\n",
    "\n",
    "# 5. 모델, 손실 함수, 옵티마이저 설정\n",
    "model = SimpleNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 6. 학습 루프 구현\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train() # 모델을 학습 모드로 설정\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device) # 데이터를 GPU로 이동\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        output = model(data) # 순전파\n",
    "        loss = criterion(output, target) # 손실 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 가중치 업데이트\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# 7. 평가 함수 구현\n",
    "def evaluate(model, device, test_loader):\n",
    "    model.eval() # 모델을 평가 모드로 설정\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # 기울기 계산 비활성화 (메모리 절약)\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # 배치별 손실 누적\n",
    "            pred = output.argmax(dim=1, keepdim=True) # 가장 높은 확률의 클래스 선택\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # 정답 개수 계산\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "# 8. 메인 함수\n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"--- Epoch {epoch}/{epochs} ---\")\n",
    "        train(model, device, train_loader, optimizer, criterion)\n",
    "        evaluate(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f2515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytouch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
